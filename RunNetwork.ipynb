{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/benjaminshare/pokemon-learning\n",
      "Warning: can't find 24 images!\n",
      "25 done!\n",
      "50 done!\n",
      "75 done!\n",
      "100 done!\n",
      "125 done!\n",
      "150 done!\n",
      "175 done!\n",
      "200 done!\n",
      "225 done!\n",
      "250 done!\n",
      "275 done!\n",
      "300 done!\n",
      "325 done!\n",
      "350 done!\n",
      "375 done!\n",
      "400 done!\n",
      "425 done!\n",
      "450 done!\n",
      "475 done!\n",
      "500 done!\n",
      "525 done!\n",
      "550 done!\n",
      "575 done!\n",
      "600 done!\n",
      "625 done!\n",
      "650 done!\n",
      "675 done!\n",
      "700 done!\n",
      "725 done!\n",
      "750 done!\n",
      "775 done!\n",
      "800 done!\n",
      "825 done!\n",
      "850 done!\n",
      "875 done!\n",
      "900 done!\n",
      "925 done!\n",
      "all 940 done!\n",
      "smallest: [14 15 29  4]\n",
      "largest: [299 188 234   4]\n",
      "x_train: (601, 128, 128, 4)\n",
      "x_val:   (151, 128, 128, 4)\n",
      "x_test:  (188, 128, 128, 4)\n",
      "y_train: (601,)\n",
      "y_val:   (151,)\n",
      "y_test:  (188,)\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import Utils.PokemonUtils as pkmnUtils\n",
    "from matplotlib import pyplot as plt\n",
    "from Models import baseline\n",
    "import importlib\n",
    "\n",
    "utils = pkmnUtils.PokemonUtils(rel_loc=\"\")\n",
    "utils.loadAllGIFs()\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = utils.generateXYSplitsV1()\n",
    "\n",
    "USE_GPU = True\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "def trainBatches(batch_size):\n",
    "    for batch in range(int(len(x_train) / batch_size)):\n",
    "        yield x_train[batch * batch_size: (batch + 1) * batch_size], y_train[batch * batch_size: (batch + 1) * batch_size]\n",
    "\n",
    "def valBatches(batch_size):\n",
    "    for batch in range(int(len(x_val) / batch_size)):\n",
    "        yield x_val[batch * batch_size: (batch + 1) * batch_size], y_val[batch * batch_size: (batch + 1) * batch_size]\n",
    "\n",
    "def testBatches(batch_size):\n",
    "    for batch in range(int(len(x_test) / batch_size)):\n",
    "        yield x_test[batch * batch_size: (batch + 1) * batch_size], y_test[batch * batch_size: (batch + 1) * batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on PokemonUtils update\n",
    "import Utils.PokemonUtils as pkmnUtils\n",
    "importlib.reload(pkmnUtils)  # update import if PokemonUtils.py changes\n",
    "utils = pkmnUtils.PokemonUtils(utils=utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Models.baseline' from '/home/benjaminshare/pokemon-learning/Models/baseline.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run on model update\n",
    "from Models import baseline\n",
    "importlib.reload(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(sess, dset, x, scores):\n",
    "    num_correct, num_samples = 0, 0\n",
    "    for x_batch, y_batch in dset:\n",
    "        feed_dict = {x: x_batch, is_training: 0}\n",
    "        scores_np = sess.run(scores, feed_dict=feed_dict)\n",
    "        y_pred = scores_np.argmax(axis=1)\n",
    "        num_samples += x_batch.shape[0]\n",
    "        num_correct += (y_pred == y_batch).sum()\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Iteration 0, loss = 27.4148\n",
      "Got 6 / 128 correct (4.69%)\n",
      "\n",
      "Iteration 10, loss = 2.9800\n",
      "Got 12 / 128 correct (9.38%)\n",
      "\n",
      "Starting epoch 1\n",
      "Iteration 20, loss = 2.8188\n",
      "Got 12 / 128 correct (9.38%)\n",
      "\n",
      "Iteration 30, loss = 2.8024\n",
      "Got 11 / 128 correct (8.59%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = baseline.ShallowNet()\n",
    "num_epochs = 2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "print_every = 10\n",
    "\n",
    "tf.reset_default_graph()    \n",
    "with tf.device(device):\n",
    "    x = tf.placeholder(tf.float32, [None, 128, 128, 4])\n",
    "    y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "    scores = model.model_init_fn(x)\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(loss)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Starting epoch %d' % epoch)\n",
    "            for x_batch, y_batch in trainBatches(batch_size):\n",
    "                feed_dict = {x: x_batch, y: y_batch, is_training:1}\n",
    "                loss_np, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "                if t % print_every == 0:\n",
    "                    print('Iteration %d, loss = %.4f' % (t, loss_np))\n",
    "                    check_accuracy(sess, valBatches(batch_size), x, scores)\n",
    "                    print()\n",
    "                t += 1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "acc = None\n",
    "pass\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
